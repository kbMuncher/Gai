{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b365e750-3b5d-4ab4-b293-c0caa7191071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae7d0b5-cfbb-4a4f-9c6f-dbd39bb782d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def onehot_encoder(position,depth):\n",
    "    onehot=torch.zeros((depth,))\n",
    "    onehot[position]=1\n",
    "    return onehot\n",
    "def int_to_onehot(number):\n",
    "    onehot=onehot_encoder(number,100)\n",
    "    return onehot\n",
    "def onehot_to_int(onehot):\n",
    "    num=torch.argmax(onehot)\n",
    "    return num.item()\n",
    "\n",
    "device ='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2c1194-4a1f-492a-88ce-a4428520af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Earlystop:\n",
    "    def __init__(self,patience=1000):\n",
    "        self.patience=patience\n",
    "        self.steps = 0\n",
    "        self.min_gdif = float('inf')\n",
    "\n",
    "    def stop(self,gdif):\n",
    "        if gdif<self.min_gdif:\n",
    "            self.min_gdif=gdif\n",
    "            self.steps=0\n",
    "        elif gdif>=self.min_gdif:\n",
    "            self.steps+=1\n",
    "        if self.steps>=self.patience:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "\n",
    "stop=Earlystop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93688b43-c0fe-4db4-a6a5-90529ba235f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([88, 71, 36, 76, 79, 26, 20, 83, 45, 43], device='cuda:0')\n",
      "tensor([77,  8, 18, 57, 80, 77, 62, 72,  5,  9], device='cuda:0')\n",
      "tensor([ 5, 51, 72, 96, 16, 69, 34, 50, 73, 13], device='cuda:0')\n",
      "tensor([38, 11, 16, 84, 69, 10, 34, 50, 72,  9], device='cuda:0')\n",
      "tensor([65, 48, 50, 87, 12, 10, 16, 82, 87, 56], device='cuda:0')\n",
      "tensor([82, 45, 82, 96, 69,  0,  8, 86, 45, 16], device='cuda:0')\n",
      "tensor([13, 66, 45, 96, 88, 16, 96, 66, 66, 16], device='cuda:0')\n",
      "tensor([50, 16, 10,  0,  0, 50, 13, 96, 16, 82], device='cuda:0')\n",
      "tensor([13,  0, 51, 45, 16,  0,  9, 45,  0, 56], device='cuda:0')\n",
      "tensor([50, 10,  8, 51, 60, 45, 26, 16, 96, 13], device='cuda:0')\n",
      "tensor([50, 26, 50, 10, 82, 16, 10, 50, 60, 33], device='cuda:0')\n",
      "tensor([66, 50, 60,  0, 50, 70, 45, 56, 82,  9], device='cuda:0')\n",
      "tensor([80, 36,  8, 50, 20, 78,  0, 96, 70, 20], device='cuda:0')\n",
      "tensor([56, 20,  0, 80,  0, 88, 85,  0, 95, 30], device='cuda:0')\n",
      "tensor([10, 16, 80, 35, 60, 20,  0, 15, 55, 45], device='cuda:0')\n",
      "tensor([20, 30,  0, 79, 26, 20, 10, 20, 70, 75], device='cuda:0')\n",
      "tensor([30, 55, 30, 95, 80, 30, 60, 20, 80, 60], device='cuda:0')\n",
      "tensor([75, 20, 70, 95, 80, 95, 80, 80, 80, 20], device='cuda:0')\n",
      "tensor([20, 20, 80, 95, 75, 80, 55, 85, 30, 20], device='cuda:0')\n",
      "tensor([ 0, 15, 95, 75, 20, 75, 85, 95, 80, 85], device='cuda:0')\n",
      "tensor([95, 65, 30, 75, 95, 30, 25, 75,  0, 80], device='cuda:0')\n",
      "tensor([95, 30, 70, 80, 70, 15, 15, 35, 80, 80], device='cuda:0')\n",
      "tensor([85, 95, 85, 95, 75, 80, 80, 30, 30, 30], device='cuda:0')\n",
      "tensor([30, 95, 85, 85, 35, 85, 40, 65, 65, 85], device='cuda:0')\n",
      "tensor([85, 85, 85, 30, 95, 85, 30, 95, 85, 40], device='cuda:0')\n",
      "tensor([55, 30, 30, 85, 35, 55, 85, 70, 35, 25], device='cuda:0')\n",
      "tensor([65, 40, 80, 85, 55, 35, 15, 25, 40, 65], device='cuda:0')\n",
      "tensor([25, 15, 15, 70, 15, 15, 65, 15, 25, 65], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def gen_sequence():\n",
    "    indices = torch.randint(0, 20, (10,))\n",
    "    values = indices*5\n",
    "    return values    \n",
    "\n",
    "def gen_batch():\n",
    "    sequence=gen_sequence()    #A\n",
    "    batch=[int_to_onehot(i).numpy() for i in sequence]    #B\n",
    "    batch=np.array(batch)\n",
    "    return torch.tensor(batch)\n",
    "batch=gen_batch()\n",
    "\n",
    "def data_to_num(data):\n",
    "    num=torch.argmax(data,dim=-1)    #A\n",
    "    return num\n",
    "numbers=data_to_num(batch) \n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "D=nn.Sequential(\n",
    "    nn.Linear(100,1),\n",
    "    nn.Sigmoid()).to(device)\n",
    "\n",
    "\n",
    "\n",
    "G=nn.Sequential(\n",
    "    nn.Linear(100,100),\n",
    "    nn.ReLU()).to(device)\n",
    "\n",
    "loss_fn=nn.BCELoss()\n",
    "lr=0.0005\n",
    "optimD=torch.optim.Adam(D.parameters(),lr=lr)\n",
    "optimG=torch.optim.Adam(G.parameters(),lr=lr)\n",
    "\n",
    "real_labels=torch.ones((10,1)).to(device)\n",
    "fake_labels=torch.zeros((10,1)).to(device)\n",
    "\n",
    "def train_D_G(D,G,loss_fn,optimD,optimG):\n",
    "    # Generate examples of real data\n",
    "    true_data=gen_batch().to(device)\n",
    "    # use 1 as labels since they are real\n",
    "    preds=D(true_data)\n",
    "    loss_D1=loss_fn(preds,real_labels.reshape(10,1))\n",
    "    optimD.zero_grad()\n",
    "    loss_D1.backward()\n",
    "    optimD.step()\n",
    "    # train D on fake data\n",
    "    noise=torch.randn(10,100).to(device)\n",
    "    generated_data=G(noise)\n",
    "    # use 0 as labels since they are fake\n",
    "    preds=D(generated_data)\n",
    "    loss_D2=loss_fn(preds,fake_labels.reshape(10,1))\n",
    "    optimD.zero_grad()\n",
    "    loss_D2.backward()\n",
    "    optimD.step()\n",
    "    \n",
    "    # train G \n",
    "    noise=torch.randn(10,100).to(device)\n",
    "    generated_data=G(noise)\n",
    "    # use 1 as labels since G wants to fool D\n",
    "    preds=D(generated_data)\n",
    "    loss_G=loss_fn(preds,real_labels.reshape(10,1))\n",
    "    optimG.zero_grad()\n",
    "    loss_G.backward()\n",
    "    optimG.step()\n",
    "    return generated_data       \n",
    "\n",
    "stopper=Earlystop(800)    #A\n",
    "\n",
    "mse=nn.MSELoss()\n",
    "real_labels=torch.ones((10,1)).to(device)\n",
    "fake_labels=torch.zeros((10,1)).to(device)\n",
    "def distance(generated_data):    #B\n",
    "    nums=data_to_num(generated_data)\n",
    "    remainders=nums%5\n",
    "    ten_zeros=torch.zeros((10,1)).to(device)\n",
    "    mseloss=mse(remainders,ten_zeros)\n",
    "    return mseloss\n",
    "\n",
    "for i in range(10000):\n",
    "    gloss=0\n",
    "    dloss=0\n",
    "    generated_data=train_D_G(D,G,loss_fn,optimD,optimG)    #C  \n",
    "    dis=distance(generated_data)\n",
    "    if stopper.stop(dis)==True:\n",
    "        break   \n",
    "    if i % 50 == 0:\n",
    "        print(data_to_num(generated_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0f802-0256-43b1-b48b-4f8dfa51e5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
